{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b74fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from io import StringIO \n",
    "# Topic model\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11f68cfe-90b5-4c23-95c4-2d461509b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dce0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_CONTENT_TYPE = \"application/json\"\n",
    "BUCKET_NAME = 'ecc-scraper-data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45f4de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from pytorch geometric lightgcn_pyg.ipynb implementation\n",
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, edge_user_post, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "        self.edge_user_post = edge_user_post\n",
    "        \n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(\n",
    "            edge_index, add_self_loops=self.add_self_loops)\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(\n",
    "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aff47ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items\n",
    "\n",
    "def load_node_csv(old_df, index_col):\n",
    "    \"\"\"Loads csv containing node information\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        index_col (str): column name of index column\n",
    "\n",
    "    Returns:\n",
    "        dict: mapping of csv row to node id\n",
    "    \"\"\"\n",
    "    df = old_df.set_index(index_col)\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc3f6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir, s3 = boto3.client('s3')):\n",
    "    objects = s3.list_objects_v2(Bucket=BUCKET_NAME)['Contents']\n",
    "    objects = list( objects)\n",
    "\n",
    "    for obj in objects:\n",
    "        if(obj['Key']=='preprocessed_data.csv'):\n",
    "            contents = s3.get_object(Bucket=BUCKET_NAME, Key=obj['Key'])\n",
    "            contents = contents['Body'].read().decode('utf-8')\n",
    "            df = pd.read_csv(StringIO(contents), index_col=0)\n",
    "            break\n",
    "\n",
    "    df.rename( columns={0 :'id'}, inplace=True )\n",
    "    \n",
    "    user_mapping = load_node_csv(df, index_col='current_user')\n",
    "    post_mapping = load_node_csv(df, index_col='post_id')\n",
    "    author_mapping = load_node_csv(df, index_col='authorUrl')\n",
    "\n",
    "    postid_text = pd.Series(df.text.values, index=df.post_id).to_dict()\n",
    "    postid_author = pd.Series(df.author.values, index=df.post_id).to_dict()\n",
    "    postid_original_user = pd.Series(df.current_user.values, index=df.post_id).to_dict()\n",
    "\n",
    "    s3.download_file(\n",
    "        'ecc-model-dump',\n",
    "        'saved_model.pt', \n",
    "        'saved_model.pt'   \n",
    "    )   \n",
    "    s3.download_file(\n",
    "        'ecc-model-dump',\n",
    "        'bert_topic_model', \n",
    "        'bert_topic_model'\n",
    "    )\n",
    "    \n",
    "    topic_model = BERTopic.load(\"bert_topic_model\")\n",
    "    model = torch.load('saved_model.pt')\n",
    "    \n",
    "    return (model, topic_model, user_mapping, post_mapping, author_mapping, postid_text, postid_author, postid_original_user, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afc690c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(serialized_input_data, content_type=JSON_CONTENT_TYPE):\n",
    "    if content_type == JSON_CONTENT_TYPE:\n",
    "        input_data = json.loads(serialized_input_data)\n",
    "        return input_data\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Requested unsupported ContentType in Accept: \" + content_type)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d2289c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(input_data, d):\n",
    "    model, topic_model = d[0], d[1]\n",
    "    user_mapping, post_mapping, author_mapping = d[2],  d[3], d[4]\n",
    "\n",
    "    postid_text, postid_author, postid_original_user = d[5], d[6], d[7]\n",
    "    \n",
    "    df = d[8]\n",
    "\n",
    "    user_id = input_data['current_user']\n",
    "    num_recs = int(input_data['n_recommendations'])\n",
    "\n",
    "\n",
    "    if user_id not in user_mapping:\n",
    "        return {'Error':'User not found'}\n",
    "\n",
    "    user = user_mapping[user_id]\n",
    "    \n",
    "    e_u = model.users_emb.weight[user]\n",
    "    scores = model.items_emb.weight @ e_u\n",
    "\n",
    "    user_pos_items = get_user_positive_items(model.edge_user_post)\n",
    "    \n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "    posts = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    post_ids = [list(post_mapping.keys())[list(post_mapping.values()).index(post)] for post in posts]\n",
    "    liked_cleaned_posts = df[df['post_id'].isin(post_ids)]\n",
    "    \n",
    "    if len(posts) == 0 or len(post_ids) == 0:\n",
    "        return {'Error':'No recommendations yet'}\n",
    "    \n",
    "    texts = [postid_text[id] for id in post_ids]\n",
    "    authors =  [postid_author[id] for id in post_ids]\n",
    "    original_users = [postid_original_user[id] for id in post_ids]\n",
    "    \n",
    "    data = {}\n",
    "    data['user'] = user_id\n",
    "\n",
    "    # TODO: Implement by merging topic modelling\n",
    "    data['recommended_topics'] = []\n",
    "\n",
    "    # stores liked and recommended posts\n",
    "    data['liked_posts'] = []\n",
    "    data['recommended_posts'] = []\n",
    "    \n",
    "    for i in range(len(post_ids)):\n",
    "        stat = liked_cleaned_posts.iloc[i]\n",
    "        print(liked_cleaned_posts.columns)\n",
    "        data['liked_posts'].append(\n",
    "            {\n",
    "                'author': authors[i],\n",
    "                'original_user': original_users[i],\n",
    "                'post_id': f\"https://www.linkedin.com/feed/update/{post_ids[i]}/\",\n",
    "                'post_body': texts[i],\n",
    "                'top_words': stat['top_words'],\n",
    "                'topic': stat['topic_name']\n",
    "            }\n",
    "        )\n",
    "\n",
    "    posts = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    post_ids = [list(post_mapping.keys())[list(post_mapping.values()).index(post)] for post in posts]\n",
    "    texts = [postid_text[id] for id in post_ids]\n",
    "    authors =  [postid_author[id] for id in post_ids]\n",
    "    original_users = [postid_original_user[id] for id in post_ids]\n",
    "    \n",
    "    reco_cleaned_posts = df[df['post_id'].isin(post_ids)]\n",
    "    \n",
    "    for i in range(len(post_ids)):\n",
    "        stat = reco_cleaned_posts.iloc[i]\n",
    "        data['recommended_posts'].append(\n",
    "            {\n",
    "                'author': authors[i],\n",
    "                'original_user': original_users[i],\n",
    "                'post_id': f\"https://www.linkedin.com/feed/update/{post_ids[i]}/\",\n",
    "                'post_body': texts[i],\n",
    "                'top_words': stat['top_words'],\n",
    "                'topic': stat['topic_name']\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90c88909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_fn(prediction_output, accept=JSON_CONTENT_TYPE):\n",
    "    print(\"recommendations\", prediction_output)\n",
    "\n",
    "    if accept == JSON_CONTENT_TYPE:\n",
    "        return json.dumps(prediction_output), accept\n",
    "\n",
    "    raise Exception(\"Requested unsupported ContentType being accepted: \" + accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "497be873-b439-434e-ab0e-cdd368aa10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', \n",
    "                          aws_access_key_id='AKIA2Z2BTOGT36MIGFYG',\n",
    "                          aws_secret_access_key='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',\n",
    "                          region_name='us-east-2'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3557fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_map = model_fn(model_dir=None,s3=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d78119f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_fn('{\"current_user\":\"skini25\", \"n_recommendations\":2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9226959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'timestamp', 'source', 'current_user', 'authorUrl',\n",
      "       'authorImage', 'author', 'text', 'n_reposts', 'n_reactions',\n",
      "       'n_comments', 'reaction', 'post_without_stopwords', 'post_lemmatized',\n",
      "       'topic_id', 'top_words', 'topic_name'],\n",
      "      dtype='object')\n",
      "Index(['post_id', 'timestamp', 'source', 'current_user', 'authorUrl',\n",
      "       'authorImage', 'author', 'text', 'n_reposts', 'n_reactions',\n",
      "       'n_comments', 'reaction', 'post_without_stopwords', 'post_lemmatized',\n",
      "       'topic_id', 'top_words', 'topic_name'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_fn(input_data, model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74c6ab9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'skini25',\n",
       " 'recommended_topics': [],\n",
       " 'liked_posts': [{'author': 'Jenna Race',\n",
       "   'original_user': 'skini25',\n",
       "   'post_id': 'https://www.linkedin.com/feed/update/urn:li:activity:7046607637613858816/',\n",
       "   'post_body': 'SpaceX is #hiring a Senior Accountant, Revenue for #starlink. Position is on-site based in Hawthorne, CA. Looking for someone with 4+ years of experience in accounting for revenue across a multinational sales cycle. SQL and Python experience a huge plus.Job post here for more details on requirements--> https://lnkd.in/guy8SjUHKnow someone? DM or comment below! #accountingjobs #financejobs #hiringnow',\n",
       "   'top_words': 'cybersecurity - award - entrylevel - innovation - pharmacy - leap - employees - commitment - tutort - gregmat',\n",
       "   'topic': '15_cybersecurity_award_entrylevel_innovation'},\n",
       "  {'author': 'Matt Gray',\n",
       "   'original_user': 'skini25',\n",
       "   'post_id': 'https://www.linkedin.com/feed/update/urn:li:activity:7049046438068056064/',\n",
       "   'post_body': 'Twitter just open-sourced their algorithm. I spent my Saturday night checking it out. There are a ton of hidden gems for growth. Here are 6 insights to increase your reach:',\n",
       "   'top_words': 'recruitment - talent - resume - coding - need - merge - experience - engineers - lego - next',\n",
       "   'topic': '0_recruitment_talent_resume_coding'}],\n",
       " 'recommended_posts': [{'author': 'Marco Lohse',\n",
       "   'original_user': 'newsstorythe-top-companies-for-career-growth-6255530',\n",
       "   'post_id': 'https://www.linkedin.com/feed/update/urn:li:activity:7054904024076046337/',\n",
       "   'post_body': 'Welcome Google DeepMind !#Google #DeepMind #GoogleDeepMind #AI',\n",
       "   'top_words': 'time - ai - value - first - correlation - prompt - visa - chatgpt - security - paper',\n",
       "   'topic': '-1_time_ai_value_first'},\n",
       "  {'author': 'Artificial Intelligence',\n",
       "   'original_user': 'kssreesha',\n",
       "   'post_id': 'https://www.linkedin.com/feed/update/urn:li:activity:7048714405286395904/',\n",
       "   'post_body': 'If you are interested in learning how to handle communication and information sharing among AI agents in multi-agent systems (MAS), you should check out our latest article. You will discover the different types of, protocols, mechanisms, and strategies of communication among AI agents, as well as the challenges and solutions involved in designing and implementing effective communication for MAS. Communication is crucial for achieving better outcomes and coordination among AI agents, but it also comes with trade-offs and risks that need to be considered. How do you approach communication and information sharing in your own MAS projects?',\n",
       "   'top_words': 'promotion - quality - growthtips - softwareengineering - techlead - focus - lead - need - managers - right',\n",
       "   'topic': '27_promotion_quality_growthtips_softwareengineering'}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list --format=freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sess = sagemaker.Session()\n",
    "sess = boto3.Session()\n",
    "role = get_execution_role()\n",
    "print(role, sess.region_name)\n",
    "instance_type = \"ml.t2.medium\"\n",
    "\n",
    "# We'll use a pytorch inference DLC image that ships with sagemaker-pytorch-inference-toolkit v2.0.6. This version includes support for Torchserve environment variables used below.\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sess.region_name ,\n",
    "    py_version=\"py39\",\n",
    "    image_scope=\"inference\",\n",
    "    version=\"1.13.1\",\n",
    "    instance_type=instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e17480",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559bd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'s3://ecc-model-dump/gnn.tar.gz'\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "     model_data='s3://ecc-model-dump/gnn.tar.gz', \n",
    "     role=role,\n",
    "     entry_point='inference.py',\n",
    "     image_uri=image_uri,\n",
    "     framework_version=\"1.13.1\",\n",
    "     code_location='s3://ecc-model-dump/models'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def invoke(endpoint_name):\n",
    "    predictor = sagemaker.predictor.Predictor(\n",
    "        endpoint_name,\n",
    "        sm_sess,\n",
    "        serializer=sagemaker.serializers.JSONSerializer(),\n",
    "        deserializer=sagemaker.deserializers.BytesDeserializer(),\n",
    "    )\n",
    "    return predictor.predict(\n",
    "        '{\"current_user\":\"kssreesha\", \"n_recommendations\":2}'\n",
    "    )\n",
    "\n",
    "\n",
    "endpoint_name = 'pytorch-inference-2023-04-21-22-52-19-808'\n",
    "# predictor.endpoint_name\n",
    "pool = multiprocessing.Pool(1)\n",
    "results = pool.map(invoke, 1 * [endpoint_name])\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
